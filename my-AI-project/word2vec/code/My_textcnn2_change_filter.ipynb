{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e875a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import mindspore\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore import ops\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "from mindspore.ops import operations as ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1293e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "gensim_model = KeyedVectors.load_word2vec_format(\n",
    "    'GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22980f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReview:\n",
    "    '''\n",
    "    影评数据集\n",
    "    '''\n",
    "    def __init__(self, root_dir, maxlen, split):\n",
    "        '''\n",
    "        input:\n",
    "            root_dir: 影评数据目录\n",
    "            maxlen: 设置句子最大长度\n",
    "            split: 设置数据集中训练/评估的比例\n",
    "        '''\n",
    "        self.path = root_dir\n",
    "        #设置两个感知映射：负样本标记为0，正样本标记为1\n",
    "        self.feelMap = {\n",
    "            'neg':0,\n",
    "            'pos':1\n",
    "        }\n",
    "        self.files = []\n",
    "\n",
    "        self.doConvert = False\n",
    "        \n",
    "        #路径确认\n",
    "        mypath = Path(self.path)\n",
    "        if not mypath.exists() or not mypath.is_dir():\n",
    "            print(\"please check the root_dir!\")\n",
    "            raise ValueError\n",
    "\n",
    "        # 在数据目录中找到文件\n",
    "        for root,_,filename in os.walk(self.path):\n",
    "            for each in filename:\n",
    "                self.files.append(os.path.join(root,each))\n",
    "            break\n",
    "\n",
    "        # 确认是否为两个文件.neg与.pos\n",
    "        if len(self.files) != 2:\n",
    "            print(\"There are {} files in the root_dir\".format(len(self.files)))\n",
    "            raise ValueError\n",
    "\n",
    "        # 读取数据\n",
    "        self.word_num = 0\n",
    "        self.maxlen = 0           \n",
    "        self.minlen = float(\"inf\") #初始化最短句子长度为正无穷\n",
    "        self.maxlen = float(\"-inf\")#初始化最长句子长度为负无穷\n",
    "        #Pos与Neg分别存储预处理后的正负样本与对应标签值0/1\n",
    "        #存储形式为\n",
    "        #负样本：[负样本的一个sentence,0]\n",
    "        #正样本：[正样本的一个sentence,1]\n",
    "        self.Pos = []\n",
    "        self.Neg = []\n",
    "        for filename in self.files:\n",
    "            #read_data即对两个文件中的sentence进行预处理（将一个句子变成其单词的集合），并对应存入Pos和Neg中\n",
    "            self.read_data(filename)\n",
    "\n",
    "        self.text2vec(maxlen=maxlen)\n",
    "        self.split_dataset(split=split)\n",
    "    #tokenize操作\n",
    "    def read_data(self, filePath):\n",
    "        with open(filePath,'r',encoding='utf-8') as f:\n",
    "            for sentence in f.readlines():\n",
    "            #将原句子中的若干符号更换成空字符串'',相当于消除这些符号\n",
    "            #个人理解是当前这些符号不是语义理解的重心，因此去除后减少待处理信息，也不会过多影响处理结果\n",
    "                sentence = sentence.replace('\\n','')\\\n",
    "                                    .replace('\"','')\\\n",
    "                                    .replace('\\'','')\\\n",
    "                                    .replace('.','')\\\n",
    "                                    .replace(',','')\\\n",
    "                                    .replace('[','')\\\n",
    "                                    .replace(']','')\\\n",
    "                                    .replace('(','')\\\n",
    "                                    .replace(')','')\\\n",
    "                                    .replace(':','')\\\n",
    "                                    .replace('--','')\\\n",
    "                                    .replace('-',' ')\\\n",
    "                                    .replace('\\\\','')\\\n",
    "                                    .replace('0','')\\\n",
    "                                    .replace('1','')\\\n",
    "                                    .replace('2','')\\\n",
    "                                    .replace('3','')\\\n",
    "                                    .replace('4','')\\\n",
    "                                    .replace('5','')\\\n",
    "                                    .replace('6','')\\\n",
    "                                    .replace('7','')\\\n",
    "                                    .replace('8','')\\\n",
    "                                    .replace('9','')\\\n",
    "                                    .replace('`','')\\\n",
    "                                    .replace('=','')\\\n",
    "                                    .replace('$','')\\\n",
    "                                    .replace('/','')\\\n",
    "                                    .replace('*','')\\\n",
    "                                    .replace(';','')\\\n",
    "                                    .replace('<b>','')\\\n",
    "                                    .replace('%','')\n",
    "                #按照空格为分隔符将sentence划分\n",
    "                sentence = sentence.split(' ')\n",
    "                #将sentence中的空字符过滤掉\n",
    "                sentence = list(filter(lambda x: x, sentence))\n",
    "                #此时sentence已经实现tokenize,如neg第一个sentence如下\n",
    "                #['simplistic', 'silly', 'and', 'tedious']\n",
    "                if sentence:\n",
    "                    self.word_num += len(sentence)\n",
    "                    self.maxlen = self.maxlen if self.maxlen >= len(sentence) else len(sentence)\n",
    "                    self.minlen = self.minlen if self.minlen <= len(sentence) else len(sentence)\n",
    "                    #给对应的sentence上标签，表示情感\n",
    "                    if 'pos' in filePath:\n",
    "                        self.Pos.append([sentence,self.feelMap['pos']])\n",
    "                    else:\n",
    "                        self.Neg.append([sentence,self.feelMap['neg']])\n",
    "    #\n",
    "    def text2vec(self, maxlen):\n",
    "        '''\n",
    "        将句子转化为向量\n",
    "\n",
    "        '''\n",
    "        # Vocab = {word : index}\n",
    "        self.Vocab = dict()\n",
    "        #先构造一个空词表\n",
    "        # self.Vocab['None']\n",
    "        for SentenceLabel in self.Pos+self.Neg:\n",
    "            vector = [0]*maxlen\n",
    "            #之前已经将sentence和其label组装到self.Pos和self.Neg中了\n",
    "            #这里SentenceLabel[0]即为sentence\n",
    "            #遍历当前sentence中的每个word\n",
    "            for index, word in enumerate(SentenceLabel[0]):\n",
    "                if index >= maxlen:\n",
    "                    break\n",
    "                #当前word未入词表，将其加入词表且更新其对应值为索引\n",
    "                if word not in self.Vocab.keys():\n",
    "                    self.Vocab[word] = len(self.Vocab)\n",
    "                    #词向量的第index的位置更新为word索引表示词表中的词\n",
    "                    vector[index] = len(self.Vocab) - 1\n",
    "                else:\n",
    "                    vector[index] = self.Vocab[word]\n",
    "            #将句子转变为向量，该句子向量类似于独热编码\n",
    "            SentenceLabel[0] = vector\n",
    "        self.doConvert = True\n",
    "    def split_dataset(self, split):\n",
    "        '''\n",
    "        分割为训练集与测试集\n",
    "\n",
    "        '''\n",
    "        #这里先把原数据集分为trunk_num份，再从中取出一份作为测试集\n",
    "        #每份大小为正样本trunk_pos_size，负样本trunk_neg_size\n",
    "        trunk_pos_size = math.ceil((1-split)*len(self.Pos))\n",
    "        trunk_neg_size = math.ceil((1-split)*len(self.Neg))\n",
    "        trunk_num = int(1/(1-split))\n",
    "        pos_temp=list()\n",
    "        neg_temp=list()\n",
    "        for index in range(trunk_num):\n",
    "            pos_temp.append(self.Pos[index*trunk_pos_size:(index+1)*trunk_pos_size])\n",
    "            neg_temp.append(self.Neg[index*trunk_neg_size:(index+1)*trunk_neg_size])\n",
    "        self.test = pos_temp.pop(2)+neg_temp.pop(2)\n",
    "        self.train = [i for item in pos_temp+neg_temp for i in item]\n",
    "\n",
    "        random.shuffle(self.train)\n",
    "        # random.shuffle(self.test)\n",
    "\n",
    "    def get_dict_len(self):\n",
    "        '''\n",
    "        获得数据集中文字组成的词典长度\n",
    "        '''\n",
    "        if self.doConvert:\n",
    "            return len(self.Vocab)\n",
    "        else:\n",
    "            print(\"Haven't finished Text2Vec\")\n",
    "            return -1\n",
    "    #打包数据集\n",
    "    def create_train_dataset(self, epoch_size, batch_size):\n",
    "        dataset = ds.GeneratorDataset(\n",
    "                                        source=Generator(input_list=self.train), \n",
    "                                        column_names=[\"data\",\"label\"], \n",
    "                                        shuffle=False\n",
    "                                        )\n",
    "        dataset=dataset.batch(batch_size=batch_size,drop_remainder=True)\n",
    "        #重复读取数据集，几个迭代就重复几次\n",
    "        dataset=dataset.repeat(epoch_size)\n",
    "        return dataset\n",
    "\n",
    "    def create_test_dataset(self, batch_size):\n",
    "        dataset = ds.GeneratorDataset(\n",
    "                                        source=Generator(input_list=self.test), \n",
    "                                        column_names=[\"data\",\"label\"], \n",
    "                                        shuffle=False\n",
    "                                        )\n",
    "        dataset=dataset.batch(batch_size=batch_size,drop_remainder=True)\n",
    "        return dataset\n",
    "    def get_vocab(self):\n",
    "        return self.Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e528a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self, input_list):\n",
    "        self.input_list=input_list\n",
    "    def __getitem__(self,item):\n",
    "        return (np.array(self.input_list[item][0],dtype=np.int32),\n",
    "                np.array(self.input_list[item][1],dtype=np.int32))\n",
    "    def __len__(self):\n",
    "        return len(self.input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512f058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造一个影评实例\n",
    "instance = MovieReview(root_dir='./data/', maxlen=51, split=0.9)\n",
    "dataset = instance.create_train_dataset(batch_size=64,epoch_size=1)\n",
    "#获取总批数\n",
    "batch_num = dataset.get_dataset_size() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5ee69",
   "metadata": {},
   "source": [
    "**使用预训练的词向量构造word_embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b579f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用字典存储词到词向量的映射\n",
    "word2Vec={}\n",
    "#将词索引转化为其对应的词\n",
    "words=[word for word in gensim_model.index_to_key[:]]\n",
    "#获取词向量并存于列表embbedings中\n",
    "embeddings=[gensim_model[word] for word in words]\n",
    "for key,value in zip(words,embeddings):\n",
    "    word2Vec[key]=value\n",
    "vocab=instance.get_vocab()\n",
    "vocab_size=instance.get_dict_len()\n",
    "ori_embeddings=np.zeros((vocab_size,300))\n",
    "for word,index in vocab.items():\n",
    "    word_vec=word2Vec.get(word,np.random.randn(300) * np.sqrt(2/300))\n",
    "    ori_embeddings[index,:]=word_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53483e6",
   "metadata": {},
   "source": [
    "**我们构建的word_embeddings中索引为0的单词对应的是'the',验证一下其词向量是否与gensim_model['the']相等**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576d3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_embeddings[0].all()==gensim_model['the'].all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccced52",
   "metadata": {},
   "source": [
    "添加<'pad'>符号的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b90808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=np.zeros_like(ori_embeddings[0])\n",
    "ori_embeddings=np.r_[ori_embeddings,[pad]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a52473",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['<pad>']=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af82a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18849, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a059c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.get_dict_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10116a5b",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b242464",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size=4\n",
    "batch_size=64\n",
    "num_classes=2\n",
    "weight_decay=3e-5\n",
    "data_path='./data/'\n",
    "keep_checkpoint_max=1\n",
    "checkpoint_path='./ckpt/train_textcnn-4_149.ckpt'\n",
    "word_len=51\n",
    "vec_length=300\n",
    "pre_trained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840c364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = []\n",
    "warm_up = [1e-3 / math.floor(epoch_size / 5) * (i + 1) for _ in range(batch_num) \n",
    "           for i in range(math.floor(epoch_size / 5))]\n",
    "shrink = [1e-3 / (16 * (i + 1)) for _ in range(batch_num) \n",
    "          for i in range(math.floor(epoch_size * 3 / 5))]\n",
    "normal_run = [1e-3 for _ in range(batch_num) for i in \n",
    "              range(epoch_size - math.floor(epoch_size / 5) \n",
    "                    - math.floor(epoch_size * 2 / 5))]\n",
    "learning_rate = learning_rate + warm_up + normal_run + shrink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969645",
   "metadata": {},
   "source": [
    "**调整卷积核需要调整下面这个cell的代码，注意更改featureMap和filter的时候记得更新dense的输入个数**  \n",
    "接下来实验步骤：\n",
    "1. 测试若干不同大小的单卷积核，寻找性能效果最佳的\n",
    "2. 在性能最佳的单卷积核领域使用多卷积核组合，确定多卷积核组合\n",
    "3. 测试不同大小的featureMap寻找性能最佳的规格，确定featureMap\n",
    "4. 修改word-embedddings为non-static(mindspore未找出实现方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c924fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化w参数\n",
    "def _weight_variable(shape, factor=0.01):\n",
    "    init_value = np.random.randn(*shape).astype(np.float32) * factor\n",
    "    return Tensor(init_value)\n",
    "\n",
    "#构造卷积层\n",
    "def make_conv_layer(kernel_size):\n",
    "    #单通道卷积核96个,提取96个特征\n",
    "    weight_shape = (96, 1, *kernel_size)\n",
    "    weight = _weight_variable(weight_shape)\n",
    "    return nn.Conv2d(in_channels=1, out_channels=96, kernel_size=kernel_size, padding=1,\n",
    "                     pad_mode=\"pad\", weight_init=weight, has_bias=True)\n",
    "\n",
    "\n",
    "class TextCNN(nn.Cell):\n",
    "    def __init__(self, vocab_len, word_len, num_classes, vec_length):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.vec_length = vec_length\n",
    "        self.word_len = word_len\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.unsqueeze = ops.ExpandDims()\n",
    "        #传入预训练词向量构造embedding层,Embedding层又可称为EmbeddingLookup层\n",
    "        #其作用是使用index id对权重矩阵对应id的向量进行查找，当输入为一个由index id组成的序列时，则查找并返回一个相同长度的矩阵\n",
    "        self.embedding = nn.Embedding(vocab_len, self.vec_length, embedding_table=Tensor((ori_embeddings),mindspore.float32))\n",
    "\n",
    "        self.slice = ops.Slice()\n",
    "        #设置三个卷积核\n",
    "        self.layer1 = self.make_layer(kernel_height=7)\n",
    "        self.layer2 = self.make_layer(kernel_height=7)\n",
    "        self.layer3 = self.make_layer(kernel_height=7)\n",
    "        self.layer4 = self.make_layer(kernel_height=7)\n",
    "        \n",
    "        self.concat = ops.Concat(1)\n",
    "        #注意修改卷积核个数时要修改全连接层的输入\n",
    "        self.fc = nn.Dense(96*4, self.num_classes)\n",
    "        #设置dropout为0.5\n",
    "        self.drop = nn.Dropout(keep_prob=0.5)\n",
    "        self.print = ops.Print()\n",
    "        self.reducemean = ops.ReduceMax(keep_dims=False)\n",
    "        \n",
    "    def make_layer(self, kernel_height):\n",
    "        return nn.SequentialCell(\n",
    "            [\n",
    "                #构造卷积层，卷积高度自定，卷积宽度均为词向量长度\n",
    "                make_conv_layer((kernel_height,self.vec_length)),\n",
    "                #ReLU为激活函数\n",
    "                nn.ReLU(),\n",
    "                #最大池化,将卷积得到的一列向量最大池化成一个元素\n",
    "                nn.MaxPool2d(kernel_size=(self.word_len-kernel_height+1,1)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def construct(self,x):\n",
    "        x = self.unsqueeze(x, 1)\n",
    "        #sentence通过词嵌入层转化为矩阵\n",
    "        x = self.embedding(x)\n",
    "        #每个layer为 卷积+激活函数+最大池化 层\n",
    "        #对sentence矩阵分别使用三个类型的卷积进行操作\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x)\n",
    "        x3 = self.layer3(x)\n",
    "        x4 = self.layer4(x)\n",
    "        \n",
    "        x1 = self.reducemean(x1, (2, 3))\n",
    "        x2 = self.reducemean(x2, (2, 3))\n",
    "        x3 = self.reducemean(x3, (2, 3))\n",
    "        x4 = self.reducemean(x4, (2, 3))\n",
    "        \n",
    "        #拼接池化层的输出作为全连接层的输入\n",
    "        x = self.concat((x1, x2, x3,x4))\n",
    "        #x=x4\n",
    "        #设置drop概率为50%，减少过拟合\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd8877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TextCNN(vocab_len=instance.get_dict_len(), word_len=word_len, \n",
    "              num_classes=num_classes, vec_length=vec_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d87d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training if set pre_trained to be True\n",
    "if pre_trained:\n",
    "    param_dict = load_checkpoint(checkpoint_path)\n",
    "    load_param_into_net(net, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a03f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = nn.Adam(filter(lambda x: x.requires_grad, net.get_parameters()), \n",
    "              learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db1b758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(net, loss_fn=loss, optimizer=opt, metrics={'acc': Accuracy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206cc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ck = CheckpointConfig(save_checkpoint_steps=int(epoch_size*batch_num/2), keep_checkpoint_max=keep_checkpoint_max)\n",
    "time_cb = TimeMonitor(data_size=batch_num)\n",
    "ckpt_save_dir = \"./ckpt\"\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"train_textcnn\", directory=ckpt_save_dir, config=config_ck)\n",
    "loss_cb = LossMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f1cdece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 0.6918609738349915\n",
      "epoch: 1 step: 2, loss is 0.6988835334777832\n",
      "epoch: 1 step: 3, loss is 0.6894785761833191\n",
      "epoch: 1 step: 4, loss is 0.6904889345169067\n",
      "epoch: 1 step: 5, loss is 0.6851993799209595\n",
      "epoch: 1 step: 6, loss is 0.689205527305603\n",
      "epoch: 1 step: 7, loss is 0.6756930351257324\n",
      "epoch: 1 step: 8, loss is 0.7156516313552856\n",
      "epoch: 1 step: 9, loss is 0.6862642765045166\n",
      "epoch: 1 step: 10, loss is 0.6857807636260986\n",
      "epoch: 1 step: 11, loss is 0.6806836128234863\n",
      "epoch: 1 step: 12, loss is 0.6798306703567505\n",
      "epoch: 1 step: 13, loss is 0.6879295706748962\n",
      "epoch: 1 step: 14, loss is 0.6887317895889282\n",
      "epoch: 1 step: 15, loss is 0.6886580586433411\n",
      "epoch: 1 step: 16, loss is 0.670509934425354\n",
      "epoch: 1 step: 17, loss is 0.6601541042327881\n",
      "epoch: 1 step: 18, loss is 0.6621108055114746\n",
      "epoch: 1 step: 19, loss is 0.6651834845542908\n",
      "epoch: 1 step: 20, loss is 0.6475258469581604\n",
      "epoch: 1 step: 21, loss is 0.6757026314735413\n",
      "epoch: 1 step: 22, loss is 0.6601787209510803\n",
      "epoch: 1 step: 23, loss is 0.6474813222885132\n",
      "epoch: 1 step: 24, loss is 0.635866641998291\n",
      "epoch: 1 step: 25, loss is 0.6424775123596191\n",
      "epoch: 1 step: 26, loss is 0.6707274913787842\n",
      "epoch: 1 step: 27, loss is 0.6553694009780884\n",
      "epoch: 1 step: 28, loss is 0.611312985420227\n",
      "epoch: 1 step: 29, loss is 0.6071380972862244\n",
      "epoch: 1 step: 30, loss is 0.6105170249938965\n",
      "epoch: 1 step: 31, loss is 0.6406142711639404\n",
      "epoch: 1 step: 32, loss is 0.6091376543045044\n",
      "epoch: 1 step: 33, loss is 0.5790460109710693\n",
      "epoch: 1 step: 34, loss is 0.5681053400039673\n",
      "epoch: 1 step: 35, loss is 0.6104977130889893\n",
      "epoch: 1 step: 36, loss is 0.6408650279045105\n",
      "epoch: 1 step: 37, loss is 0.6742790937423706\n",
      "epoch: 1 step: 38, loss is 0.5815374851226807\n",
      "epoch: 1 step: 39, loss is 0.5700968503952026\n",
      "epoch: 1 step: 40, loss is 0.6233152151107788\n",
      "epoch: 1 step: 41, loss is 0.5740309953689575\n",
      "epoch: 1 step: 42, loss is 0.5581256151199341\n",
      "epoch: 1 step: 43, loss is 0.5755851864814758\n",
      "epoch: 1 step: 44, loss is 0.5543856620788574\n",
      "epoch: 1 step: 45, loss is 0.5566610097885132\n",
      "epoch: 1 step: 46, loss is 0.5563908219337463\n",
      "epoch: 1 step: 47, loss is 0.5641584396362305\n",
      "epoch: 1 step: 48, loss is 0.5595240592956543\n",
      "epoch: 1 step: 49, loss is 0.4643581509590149\n",
      "epoch: 1 step: 50, loss is 0.5516481399536133\n",
      "epoch: 1 step: 51, loss is 0.5571318864822388\n",
      "epoch: 1 step: 52, loss is 0.5007058382034302\n",
      "epoch: 1 step: 53, loss is 0.5175926685333252\n",
      "epoch: 1 step: 54, loss is 0.5061663389205933\n",
      "epoch: 1 step: 55, loss is 0.5116809606552124\n",
      "epoch: 1 step: 56, loss is 0.5098422765731812\n",
      "epoch: 1 step: 57, loss is 0.5984588861465454\n",
      "epoch: 1 step: 58, loss is 0.536893367767334\n",
      "epoch: 1 step: 59, loss is 0.5175581574440002\n",
      "epoch: 1 step: 60, loss is 0.4897654950618744\n",
      "epoch: 1 step: 61, loss is 0.6069103479385376\n",
      "epoch: 1 step: 62, loss is 0.47513043880462646\n",
      "epoch: 1 step: 63, loss is 0.5662776827812195\n",
      "epoch: 1 step: 64, loss is 0.34112876653671265\n",
      "epoch: 1 step: 65, loss is 0.570746660232544\n",
      "epoch: 1 step: 66, loss is 0.49719154834747314\n",
      "epoch: 1 step: 67, loss is 0.5175927877426147\n",
      "epoch: 1 step: 68, loss is 0.4878564774990082\n",
      "epoch: 1 step: 69, loss is 0.5345032215118408\n",
      "epoch: 1 step: 70, loss is 0.43920695781707764\n",
      "epoch: 1 step: 71, loss is 0.46445247530937195\n",
      "epoch: 1 step: 72, loss is 0.3926169276237488\n",
      "epoch: 1 step: 73, loss is 0.5575428009033203\n",
      "epoch: 1 step: 74, loss is 0.5886433720588684\n",
      "epoch: 1 step: 75, loss is 0.5298112630844116\n",
      "epoch: 1 step: 76, loss is 0.48479020595550537\n",
      "epoch: 1 step: 77, loss is 0.38674116134643555\n",
      "epoch: 1 step: 78, loss is 0.4703655242919922\n",
      "epoch: 1 step: 79, loss is 0.5963072776794434\n",
      "epoch: 1 step: 80, loss is 0.5045519471168518\n",
      "epoch: 1 step: 81, loss is 0.5357954502105713\n",
      "epoch: 1 step: 82, loss is 0.4531427025794983\n",
      "epoch: 1 step: 83, loss is 0.5366595983505249\n",
      "epoch: 1 step: 84, loss is 0.48879778385162354\n",
      "epoch: 1 step: 85, loss is 0.49051517248153687\n",
      "epoch: 1 step: 86, loss is 0.5515539050102234\n",
      "epoch: 1 step: 87, loss is 0.4803532361984253\n",
      "epoch: 1 step: 88, loss is 0.45145976543426514\n",
      "epoch: 1 step: 89, loss is 0.46741819381713867\n",
      "epoch: 1 step: 90, loss is 0.4763428568840027\n",
      "epoch: 1 step: 91, loss is 0.5316728353500366\n",
      "epoch: 1 step: 92, loss is 0.4792013168334961\n",
      "epoch: 1 step: 93, loss is 0.4619036614894867\n",
      "epoch: 1 step: 94, loss is 0.45152586698532104\n",
      "epoch: 1 step: 95, loss is 0.5071552991867065\n",
      "epoch: 1 step: 96, loss is 0.4647989273071289\n",
      "epoch: 1 step: 97, loss is 0.4274865686893463\n",
      "epoch: 1 step: 98, loss is 0.4067610502243042\n",
      "epoch: 1 step: 99, loss is 0.38367995619773865\n",
      "epoch: 1 step: 100, loss is 0.5704403519630432\n",
      "epoch: 1 step: 101, loss is 0.5071241855621338\n",
      "epoch: 1 step: 102, loss is 0.4409750998020172\n",
      "epoch: 1 step: 103, loss is 0.5368802547454834\n",
      "epoch: 1 step: 104, loss is 0.5842680335044861\n",
      "epoch: 1 step: 105, loss is 0.4250139892101288\n",
      "epoch: 1 step: 106, loss is 0.5054713487625122\n",
      "epoch: 1 step: 107, loss is 0.47327524423599243\n",
      "epoch: 1 step: 108, loss is 0.5338390469551086\n",
      "epoch: 1 step: 109, loss is 0.45005205273628235\n",
      "epoch: 1 step: 110, loss is 0.4647727310657501\n",
      "epoch: 1 step: 111, loss is 0.4852059483528137\n",
      "epoch: 1 step: 112, loss is 0.4440765380859375\n",
      "epoch: 1 step: 113, loss is 0.380196213722229\n",
      "epoch: 1 step: 114, loss is 0.475087434053421\n",
      "epoch: 1 step: 115, loss is 0.4494876563549042\n",
      "epoch: 1 step: 116, loss is 0.4206963777542114\n",
      "epoch: 1 step: 117, loss is 0.5603578090667725\n",
      "epoch: 1 step: 118, loss is 0.40183812379837036\n",
      "epoch: 1 step: 119, loss is 0.3836185932159424\n",
      "epoch: 1 step: 120, loss is 0.4612477123737335\n",
      "epoch: 1 step: 121, loss is 0.48208707571029663\n",
      "epoch: 1 step: 122, loss is 0.3944689929485321\n",
      "epoch: 1 step: 123, loss is 0.427387535572052\n",
      "epoch: 1 step: 124, loss is 0.3743319511413574\n",
      "epoch: 1 step: 125, loss is 0.4112774729728699\n",
      "epoch: 1 step: 126, loss is 0.4589850902557373\n",
      "epoch: 1 step: 127, loss is 0.5209745168685913\n",
      "epoch: 1 step: 128, loss is 0.5691076517105103\n",
      "epoch: 1 step: 129, loss is 0.46904924511909485\n",
      "epoch: 1 step: 130, loss is 0.3736504912376404\n",
      "epoch: 1 step: 131, loss is 0.48076820373535156\n",
      "epoch: 1 step: 132, loss is 0.3991369605064392\n",
      "epoch: 1 step: 133, loss is 0.49774056673049927\n",
      "epoch: 1 step: 134, loss is 0.4451608657836914\n",
      "epoch: 1 step: 135, loss is 0.40485742688179016\n",
      "epoch: 1 step: 136, loss is 0.36985746026039124\n",
      "epoch: 1 step: 137, loss is 0.375596821308136\n",
      "epoch: 1 step: 138, loss is 0.4238413870334625\n",
      "epoch: 1 step: 139, loss is 0.51728355884552\n",
      "epoch: 1 step: 140, loss is 0.47793397307395935\n",
      "epoch: 1 step: 141, loss is 0.4321441650390625\n",
      "epoch: 1 step: 142, loss is 0.48082786798477173\n",
      "epoch: 1 step: 143, loss is 0.33727729320526123\n",
      "epoch: 1 step: 144, loss is 0.4844003915786743\n",
      "epoch: 1 step: 145, loss is 0.4735449254512787\n",
      "epoch: 1 step: 146, loss is 0.5433754920959473\n",
      "epoch: 1 step: 147, loss is 0.3566918969154358\n",
      "epoch: 1 step: 148, loss is 0.3850286602973938\n",
      "epoch: 1 step: 149, loss is 0.6660772562026978\n",
      "Train epoch time: 100368.736 ms, per step time: 673.616 ms\n",
      "epoch: 2 step: 1, loss is 0.3896816372871399\n",
      "epoch: 2 step: 2, loss is 0.44067269563674927\n",
      "epoch: 2 step: 3, loss is 0.40327179431915283\n",
      "epoch: 2 step: 4, loss is 0.39255276322364807\n",
      "epoch: 2 step: 5, loss is 0.41145026683807373\n",
      "epoch: 2 step: 6, loss is 0.526758074760437\n",
      "epoch: 2 step: 7, loss is 0.3335215151309967\n",
      "epoch: 2 step: 8, loss is 0.5103684663772583\n",
      "epoch: 2 step: 9, loss is 0.3480737805366516\n",
      "epoch: 2 step: 10, loss is 0.3396911919116974\n",
      "epoch: 2 step: 11, loss is 0.33738377690315247\n",
      "epoch: 2 step: 12, loss is 0.37889012694358826\n",
      "epoch: 2 step: 13, loss is 0.33892032504081726\n",
      "epoch: 2 step: 14, loss is 0.3716886043548584\n",
      "epoch: 2 step: 15, loss is 0.3544193208217621\n",
      "epoch: 2 step: 16, loss is 0.27789533138275146\n",
      "epoch: 2 step: 17, loss is 0.18697679042816162\n",
      "epoch: 2 step: 18, loss is 0.3201846778392792\n",
      "epoch: 2 step: 19, loss is 0.38073718547821045\n",
      "epoch: 2 step: 20, loss is 0.3631485104560852\n",
      "epoch: 2 step: 21, loss is 0.36673134565353394\n",
      "epoch: 2 step: 22, loss is 0.29394400119781494\n",
      "epoch: 2 step: 23, loss is 0.24935589730739594\n",
      "epoch: 2 step: 24, loss is 0.3099122643470764\n",
      "epoch: 2 step: 25, loss is 0.3246385455131531\n",
      "epoch: 2 step: 26, loss is 0.4098559021949768\n",
      "epoch: 2 step: 27, loss is 0.342678964138031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 28, loss is 0.2852814197540283\n",
      "epoch: 2 step: 29, loss is 0.20917730033397675\n",
      "epoch: 2 step: 30, loss is 0.19008232653141022\n",
      "epoch: 2 step: 31, loss is 0.32483553886413574\n",
      "epoch: 2 step: 32, loss is 0.26633816957473755\n",
      "epoch: 2 step: 33, loss is 0.272802472114563\n",
      "epoch: 2 step: 34, loss is 0.21644848585128784\n",
      "epoch: 2 step: 35, loss is 0.24836848676204681\n",
      "epoch: 2 step: 36, loss is 0.33973342180252075\n",
      "epoch: 2 step: 37, loss is 0.3414191007614136\n",
      "epoch: 2 step: 38, loss is 0.27293097972869873\n",
      "epoch: 2 step: 39, loss is 0.34876102209091187\n",
      "epoch: 2 step: 40, loss is 0.23776692152023315\n",
      "epoch: 2 step: 41, loss is 0.2562500834465027\n",
      "epoch: 2 step: 42, loss is 0.2170763611793518\n",
      "epoch: 2 step: 43, loss is 0.2893419861793518\n",
      "epoch: 2 step: 44, loss is 0.2904369831085205\n",
      "epoch: 2 step: 45, loss is 0.22009125351905823\n",
      "epoch: 2 step: 46, loss is 0.23954187333583832\n",
      "epoch: 2 step: 47, loss is 0.22644761204719543\n",
      "epoch: 2 step: 48, loss is 0.230582594871521\n",
      "epoch: 2 step: 49, loss is 0.17746224999427795\n",
      "epoch: 2 step: 50, loss is 0.24139103293418884\n",
      "epoch: 2 step: 51, loss is 0.30729007720947266\n",
      "epoch: 2 step: 52, loss is 0.213415265083313\n",
      "epoch: 2 step: 53, loss is 0.1872481256723404\n",
      "epoch: 2 step: 54, loss is 0.18387973308563232\n",
      "epoch: 2 step: 55, loss is 0.24656221270561218\n",
      "epoch: 2 step: 56, loss is 0.14243102073669434\n",
      "epoch: 2 step: 57, loss is 0.3116747736930847\n",
      "epoch: 2 step: 58, loss is 0.23629426956176758\n",
      "epoch: 2 step: 59, loss is 0.20699596405029297\n",
      "epoch: 2 step: 60, loss is 0.1844024509191513\n",
      "epoch: 2 step: 61, loss is 0.3266291618347168\n",
      "epoch: 2 step: 62, loss is 0.1330394297838211\n",
      "epoch: 2 step: 63, loss is 0.23118627071380615\n",
      "epoch: 2 step: 64, loss is 0.11100058257579803\n",
      "epoch: 2 step: 65, loss is 0.27326101064682007\n",
      "epoch: 2 step: 66, loss is 0.18244993686676025\n",
      "epoch: 2 step: 67, loss is 0.1897393763065338\n",
      "epoch: 2 step: 68, loss is 0.11996319144964218\n",
      "epoch: 2 step: 69, loss is 0.21929381787776947\n",
      "epoch: 2 step: 70, loss is 0.1299179196357727\n",
      "epoch: 2 step: 71, loss is 0.22793786227703094\n",
      "epoch: 2 step: 72, loss is 0.12315487116575241\n",
      "epoch: 2 step: 73, loss is 0.17171992361545563\n",
      "epoch: 2 step: 74, loss is 0.2669166326522827\n",
      "epoch: 2 step: 75, loss is 0.1687639355659485\n",
      "epoch: 2 step: 76, loss is 0.17472049593925476\n",
      "epoch: 2 step: 77, loss is 0.11570154130458832\n",
      "epoch: 2 step: 78, loss is 0.16988544166088104\n",
      "epoch: 2 step: 79, loss is 0.2583273947238922\n",
      "epoch: 2 step: 80, loss is 0.20308926701545715\n",
      "epoch: 2 step: 81, loss is 0.1847190260887146\n",
      "epoch: 2 step: 82, loss is 0.12040504068136215\n",
      "epoch: 2 step: 83, loss is 0.14563286304473877\n",
      "epoch: 2 step: 84, loss is 0.18931059539318085\n",
      "epoch: 2 step: 85, loss is 0.14015743136405945\n",
      "epoch: 2 step: 86, loss is 0.15668469667434692\n",
      "epoch: 2 step: 87, loss is 0.19730468094348907\n",
      "epoch: 2 step: 88, loss is 0.18334989249706268\n",
      "epoch: 2 step: 89, loss is 0.14150816202163696\n",
      "epoch: 2 step: 90, loss is 0.1746475100517273\n",
      "epoch: 2 step: 91, loss is 0.216274693608284\n",
      "epoch: 2 step: 92, loss is 0.1334550678730011\n",
      "epoch: 2 step: 93, loss is 0.14852121472358704\n",
      "epoch: 2 step: 94, loss is 0.16918231546878815\n",
      "epoch: 2 step: 95, loss is 0.21620279550552368\n",
      "epoch: 2 step: 96, loss is 0.12915638089179993\n",
      "epoch: 2 step: 97, loss is 0.1534315049648285\n",
      "epoch: 2 step: 98, loss is 0.14177018404006958\n",
      "epoch: 2 step: 99, loss is 0.13196595013141632\n",
      "epoch: 2 step: 100, loss is 0.20522817969322205\n",
      "epoch: 2 step: 101, loss is 0.12413845956325531\n",
      "epoch: 2 step: 102, loss is 0.13791188597679138\n",
      "epoch: 2 step: 103, loss is 0.215358704328537\n",
      "epoch: 2 step: 104, loss is 0.19229164719581604\n",
      "epoch: 2 step: 105, loss is 0.11880634725093842\n",
      "epoch: 2 step: 106, loss is 0.15558768808841705\n",
      "epoch: 2 step: 107, loss is 0.18335098028182983\n",
      "epoch: 2 step: 108, loss is 0.16689054667949677\n",
      "epoch: 2 step: 109, loss is 0.10740771889686584\n",
      "epoch: 2 step: 110, loss is 0.13654275238513947\n",
      "epoch: 2 step: 111, loss is 0.17749238014221191\n",
      "epoch: 2 step: 112, loss is 0.14925768971443176\n",
      "epoch: 2 step: 113, loss is 0.12402531504631042\n",
      "epoch: 2 step: 114, loss is 0.1664516180753708\n",
      "epoch: 2 step: 115, loss is 0.12415330111980438\n",
      "epoch: 2 step: 116, loss is 0.12343181669712067\n",
      "epoch: 2 step: 117, loss is 0.24992558360099792\n",
      "epoch: 2 step: 118, loss is 0.09166518598794937\n",
      "epoch: 2 step: 119, loss is 0.12752775847911835\n",
      "epoch: 2 step: 120, loss is 0.1556801050901413\n",
      "epoch: 2 step: 121, loss is 0.19888779520988464\n",
      "epoch: 2 step: 122, loss is 0.13587361574172974\n",
      "epoch: 2 step: 123, loss is 0.1294141560792923\n",
      "epoch: 2 step: 124, loss is 0.11476665735244751\n",
      "epoch: 2 step: 125, loss is 0.1427116096019745\n",
      "epoch: 2 step: 126, loss is 0.16366875171661377\n",
      "epoch: 2 step: 127, loss is 0.1809121072292328\n",
      "epoch: 2 step: 128, loss is 0.1562463492155075\n",
      "epoch: 2 step: 129, loss is 0.17759908735752106\n",
      "epoch: 2 step: 130, loss is 0.12575505673885345\n",
      "epoch: 2 step: 131, loss is 0.11308970302343369\n",
      "epoch: 2 step: 132, loss is 0.1218920573592186\n",
      "epoch: 2 step: 133, loss is 0.1536152958869934\n",
      "epoch: 2 step: 134, loss is 0.0996331125497818\n",
      "epoch: 2 step: 135, loss is 0.07659098505973816\n",
      "epoch: 2 step: 136, loss is 0.10336031019687653\n",
      "epoch: 2 step: 137, loss is 0.11937253177165985\n",
      "epoch: 2 step: 138, loss is 0.11438775062561035\n",
      "epoch: 2 step: 139, loss is 0.1639266163110733\n",
      "epoch: 2 step: 140, loss is 0.15762172639369965\n",
      "epoch: 2 step: 141, loss is 0.1506997048854828\n",
      "epoch: 2 step: 142, loss is 0.16638228297233582\n",
      "epoch: 2 step: 143, loss is 0.07054092735052109\n",
      "epoch: 2 step: 144, loss is 0.14913812279701233\n",
      "epoch: 2 step: 145, loss is 0.09765996038913727\n",
      "epoch: 2 step: 146, loss is 0.196658194065094\n",
      "epoch: 2 step: 147, loss is 0.07026765495538712\n",
      "epoch: 2 step: 148, loss is 0.12068622559309006\n",
      "epoch: 2 step: 149, loss is 0.23378267884254456\n",
      "Train epoch time: 98158.556 ms, per step time: 658.782 ms\n",
      "epoch: 3 step: 1, loss is 0.06722910702228546\n",
      "epoch: 3 step: 2, loss is 0.13173426687717438\n",
      "epoch: 3 step: 3, loss is 0.08780523389577866\n",
      "epoch: 3 step: 4, loss is 0.10173782706260681\n",
      "epoch: 3 step: 5, loss is 0.09222047030925751\n",
      "epoch: 3 step: 6, loss is 0.12177064269781113\n",
      "epoch: 3 step: 7, loss is 0.07718013226985931\n",
      "epoch: 3 step: 8, loss is 0.13807538151741028\n",
      "epoch: 3 step: 9, loss is 0.12958551943302155\n",
      "epoch: 3 step: 10, loss is 0.07827192544937134\n",
      "epoch: 3 step: 11, loss is 0.11894723027944565\n",
      "epoch: 3 step: 12, loss is 0.17090418934822083\n",
      "epoch: 3 step: 13, loss is 0.0520046204328537\n",
      "epoch: 3 step: 14, loss is 0.09287317097187042\n",
      "epoch: 3 step: 15, loss is 0.06749965995550156\n",
      "epoch: 3 step: 16, loss is 0.09636209905147552\n",
      "epoch: 3 step: 17, loss is 0.02722688391804695\n",
      "epoch: 3 step: 18, loss is 0.061401594430208206\n",
      "epoch: 3 step: 19, loss is 0.09474094212055206\n",
      "epoch: 3 step: 20, loss is 0.08468876779079437\n",
      "epoch: 3 step: 21, loss is 0.0980856791138649\n",
      "epoch: 3 step: 22, loss is 0.058938346803188324\n",
      "epoch: 3 step: 23, loss is 0.07732175290584564\n",
      "epoch: 3 step: 24, loss is 0.07152744382619858\n",
      "epoch: 3 step: 25, loss is 0.04976688325405121\n",
      "epoch: 3 step: 26, loss is 0.11037597060203552\n",
      "epoch: 3 step: 27, loss is 0.12487078458070755\n",
      "epoch: 3 step: 28, loss is 0.06460388004779816\n",
      "epoch: 3 step: 29, loss is 0.05641727149486542\n",
      "epoch: 3 step: 30, loss is 0.03244686871767044\n",
      "epoch: 3 step: 31, loss is 0.05481475964188576\n",
      "epoch: 3 step: 32, loss is 0.04760719835758209\n",
      "epoch: 3 step: 33, loss is 0.0450921356678009\n",
      "epoch: 3 step: 34, loss is 0.024587491527199745\n",
      "epoch: 3 step: 35, loss is 0.0621596984565258\n",
      "epoch: 3 step: 36, loss is 0.08772727102041245\n",
      "epoch: 3 step: 37, loss is 0.07909250259399414\n",
      "epoch: 3 step: 38, loss is 0.04867173731327057\n",
      "epoch: 3 step: 39, loss is 0.06266224384307861\n",
      "epoch: 3 step: 40, loss is 0.03775086626410484\n",
      "epoch: 3 step: 41, loss is 0.04109461233019829\n",
      "epoch: 3 step: 42, loss is 0.06919977068901062\n",
      "epoch: 3 step: 43, loss is 0.05555650591850281\n",
      "epoch: 3 step: 44, loss is 0.052400682121515274\n",
      "epoch: 3 step: 45, loss is 0.03497902303934097\n",
      "epoch: 3 step: 46, loss is 0.03986884653568268\n",
      "epoch: 3 step: 47, loss is 0.03498883917927742\n",
      "epoch: 3 step: 48, loss is 0.04275770112872124\n",
      "epoch: 3 step: 49, loss is 0.037066370248794556\n",
      "epoch: 3 step: 50, loss is 0.03721962869167328\n",
      "epoch: 3 step: 51, loss is 0.05247125029563904\n",
      "epoch: 3 step: 52, loss is 0.07593773305416107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 53, loss is 0.02618754468858242\n",
      "epoch: 3 step: 54, loss is 0.03742952644824982\n",
      "epoch: 3 step: 55, loss is 0.09847600013017654\n",
      "epoch: 3 step: 56, loss is 0.024839142337441444\n",
      "epoch: 3 step: 57, loss is 0.04618028178811073\n",
      "epoch: 3 step: 58, loss is 0.027759436517953873\n",
      "epoch: 3 step: 59, loss is 0.039830561727285385\n",
      "epoch: 3 step: 60, loss is 0.02173733338713646\n",
      "epoch: 3 step: 61, loss is 0.10588110983371735\n",
      "epoch: 3 step: 62, loss is 0.039596155285835266\n",
      "epoch: 3 step: 63, loss is 0.08383962512016296\n",
      "epoch: 3 step: 64, loss is 0.024854382500052452\n",
      "epoch: 3 step: 65, loss is 0.02471567690372467\n",
      "epoch: 3 step: 66, loss is 0.026110824197530746\n",
      "epoch: 3 step: 67, loss is 0.043494872748851776\n",
      "epoch: 3 step: 68, loss is 0.014806743711233139\n",
      "epoch: 3 step: 69, loss is 0.068629689514637\n",
      "epoch: 3 step: 70, loss is 0.011225176975131035\n",
      "epoch: 3 step: 71, loss is 0.04176764935255051\n",
      "epoch: 3 step: 72, loss is 0.021836794912815094\n",
      "epoch: 3 step: 73, loss is 0.022302303463220596\n",
      "epoch: 3 step: 74, loss is 0.036750372499227524\n",
      "epoch: 3 step: 75, loss is 0.03018874302506447\n",
      "epoch: 3 step: 76, loss is 0.033903658390045166\n",
      "epoch: 3 step: 77, loss is 0.01633908599615097\n",
      "epoch: 3 step: 78, loss is 0.022913817316293716\n",
      "epoch: 3 step: 79, loss is 0.04391014203429222\n",
      "epoch: 3 step: 80, loss is 0.03098255768418312\n",
      "epoch: 3 step: 81, loss is 0.01457975059747696\n",
      "epoch: 3 step: 82, loss is 0.013907955028116703\n",
      "epoch: 3 step: 83, loss is 0.021609188988804817\n",
      "epoch: 3 step: 84, loss is 0.020232658833265305\n",
      "epoch: 3 step: 85, loss is 0.016014087945222855\n",
      "epoch: 3 step: 86, loss is 0.01553561445325613\n",
      "epoch: 3 step: 87, loss is 0.03805075213313103\n",
      "epoch: 3 step: 88, loss is 0.0337960347533226\n",
      "epoch: 3 step: 89, loss is 0.020729754120111465\n",
      "epoch: 3 step: 90, loss is 0.0225997231900692\n",
      "epoch: 3 step: 91, loss is 0.04163146764039993\n",
      "epoch: 3 step: 92, loss is 0.02045711688697338\n",
      "epoch: 3 step: 93, loss is 0.015112753957509995\n",
      "epoch: 3 step: 94, loss is 0.030673585832118988\n",
      "epoch: 3 step: 95, loss is 0.030790355056524277\n",
      "epoch: 3 step: 96, loss is 0.015346957370638847\n",
      "epoch: 3 step: 97, loss is 0.019543416798114777\n",
      "epoch: 3 step: 98, loss is 0.017122570425271988\n",
      "epoch: 3 step: 99, loss is 0.021029163151979446\n",
      "epoch: 3 step: 100, loss is 0.03507406264543533\n",
      "epoch: 3 step: 101, loss is 0.01950114779174328\n",
      "epoch: 3 step: 102, loss is 0.01871674507856369\n",
      "epoch: 3 step: 103, loss is 0.015627872198820114\n",
      "epoch: 3 step: 104, loss is 0.05879603326320648\n",
      "epoch: 3 step: 105, loss is 0.015738945454359055\n",
      "epoch: 3 step: 106, loss is 0.025953691452741623\n",
      "epoch: 3 step: 107, loss is 0.02803937904536724\n",
      "epoch: 3 step: 108, loss is 0.01671769469976425\n",
      "epoch: 3 step: 109, loss is 0.01900099590420723\n",
      "epoch: 3 step: 110, loss is 0.021626168861985207\n",
      "epoch: 3 step: 111, loss is 0.026765156537294388\n",
      "epoch: 3 step: 112, loss is 0.018079407513141632\n",
      "epoch: 3 step: 113, loss is 0.018730048090219498\n",
      "epoch: 3 step: 114, loss is 0.016592103987932205\n",
      "epoch: 3 step: 115, loss is 0.014694280922412872\n",
      "epoch: 3 step: 116, loss is 0.018489358946681023\n",
      "epoch: 3 step: 117, loss is 0.04662950709462166\n",
      "epoch: 3 step: 118, loss is 0.024980414658784866\n",
      "epoch: 3 step: 119, loss is 0.024420280009508133\n",
      "epoch: 3 step: 120, loss is 0.015155690722167492\n",
      "epoch: 3 step: 121, loss is 0.03013940155506134\n",
      "epoch: 3 step: 122, loss is 0.012594221159815788\n",
      "epoch: 3 step: 123, loss is 0.010779712349176407\n",
      "epoch: 3 step: 124, loss is 0.010606164112687111\n",
      "epoch: 3 step: 125, loss is 0.01281401515007019\n",
      "epoch: 3 step: 126, loss is 0.023807141929864883\n",
      "epoch: 3 step: 127, loss is 0.012270139530301094\n",
      "epoch: 3 step: 128, loss is 0.0291968435049057\n",
      "epoch: 3 step: 129, loss is 0.011355884373188019\n",
      "epoch: 3 step: 130, loss is 0.012554697692394257\n",
      "epoch: 3 step: 131, loss is 0.01203741692006588\n",
      "epoch: 3 step: 132, loss is 0.007125336676836014\n",
      "epoch: 3 step: 133, loss is 0.010991604067385197\n",
      "epoch: 3 step: 134, loss is 0.015201272442936897\n",
      "epoch: 3 step: 135, loss is 0.012540153227746487\n",
      "epoch: 3 step: 136, loss is 0.008444035425782204\n",
      "epoch: 3 step: 137, loss is 0.008639739826321602\n",
      "epoch: 3 step: 138, loss is 0.00881377886980772\n",
      "epoch: 3 step: 139, loss is 0.023548483848571777\n",
      "epoch: 3 step: 140, loss is 0.021154649555683136\n",
      "epoch: 3 step: 141, loss is 0.019392631947994232\n",
      "epoch: 3 step: 142, loss is 0.011707392521202564\n",
      "epoch: 3 step: 143, loss is 0.008622167631983757\n",
      "epoch: 3 step: 144, loss is 0.009933508932590485\n",
      "epoch: 3 step: 145, loss is 0.008605677634477615\n",
      "epoch: 3 step: 146, loss is 0.012347455136477947\n",
      "epoch: 3 step: 147, loss is 0.00823364220559597\n",
      "epoch: 3 step: 148, loss is 0.028420861810445786\n",
      "epoch: 3 step: 149, loss is 0.029390661045908928\n",
      "Train epoch time: 101206.846 ms, per step time: 679.241 ms\n",
      "epoch: 4 step: 1, loss is 0.02524487115442753\n",
      "epoch: 4 step: 2, loss is 0.011151622980833054\n",
      "epoch: 4 step: 3, loss is 0.013850631192326546\n",
      "epoch: 4 step: 4, loss is 0.011862059123814106\n",
      "epoch: 4 step: 5, loss is 0.010892564430832863\n",
      "epoch: 4 step: 6, loss is 0.015814965590834618\n",
      "epoch: 4 step: 7, loss is 0.007947836071252823\n",
      "epoch: 4 step: 8, loss is 0.012409544549882412\n",
      "epoch: 4 step: 9, loss is 0.006656945683062077\n",
      "epoch: 4 step: 10, loss is 0.009168779477477074\n",
      "epoch: 4 step: 11, loss is 0.009215660393238068\n",
      "epoch: 4 step: 12, loss is 0.011079122312366962\n",
      "epoch: 4 step: 13, loss is 0.005142197012901306\n",
      "epoch: 4 step: 14, loss is 0.010580419562757015\n",
      "epoch: 4 step: 15, loss is 0.028412936255335808\n",
      "epoch: 4 step: 16, loss is 0.030949991196393967\n",
      "epoch: 4 step: 17, loss is 0.006292295176535845\n",
      "epoch: 4 step: 18, loss is 0.02049015648663044\n",
      "epoch: 4 step: 19, loss is 0.014674464240670204\n",
      "epoch: 4 step: 20, loss is 0.019842479377985\n",
      "epoch: 4 step: 21, loss is 0.012618789449334145\n",
      "epoch: 4 step: 22, loss is 0.014875145629048347\n",
      "epoch: 4 step: 23, loss is 0.007176687475293875\n",
      "epoch: 4 step: 24, loss is 0.011866803281009197\n",
      "epoch: 4 step: 25, loss is 0.008778714574873447\n",
      "epoch: 4 step: 26, loss is 0.014193547889590263\n",
      "epoch: 4 step: 27, loss is 0.007956214249134064\n",
      "epoch: 4 step: 28, loss is 0.007201259955763817\n",
      "epoch: 4 step: 29, loss is 0.007896753028035164\n",
      "epoch: 4 step: 30, loss is 0.0043958136811852455\n",
      "epoch: 4 step: 31, loss is 0.009195869788527489\n",
      "epoch: 4 step: 32, loss is 0.006250592879951\n",
      "epoch: 4 step: 33, loss is 0.009645992890000343\n",
      "epoch: 4 step: 34, loss is 0.012698030099272728\n",
      "epoch: 4 step: 35, loss is 0.013744588941335678\n",
      "epoch: 4 step: 36, loss is 0.015286664478480816\n",
      "epoch: 4 step: 37, loss is 0.007961292751133442\n",
      "epoch: 4 step: 38, loss is 0.012901855632662773\n",
      "epoch: 4 step: 39, loss is 0.010730233043432236\n",
      "epoch: 4 step: 40, loss is 0.006596703547984362\n",
      "epoch: 4 step: 41, loss is 0.009138391353189945\n",
      "epoch: 4 step: 42, loss is 0.008892366662621498\n",
      "epoch: 4 step: 43, loss is 0.007222823798656464\n",
      "epoch: 4 step: 44, loss is 0.010775023140013218\n",
      "epoch: 4 step: 45, loss is 0.006238897331058979\n",
      "epoch: 4 step: 46, loss is 0.006632172968238592\n",
      "epoch: 4 step: 47, loss is 0.005785470828413963\n",
      "epoch: 4 step: 48, loss is 0.007263112347573042\n",
      "epoch: 4 step: 49, loss is 0.009130608290433884\n",
      "epoch: 4 step: 50, loss is 0.0052937110885977745\n",
      "epoch: 4 step: 51, loss is 0.005173997487872839\n",
      "epoch: 4 step: 52, loss is 0.008864935487508774\n",
      "epoch: 4 step: 53, loss is 0.005241055972874165\n",
      "epoch: 4 step: 54, loss is 0.00586819788441062\n",
      "epoch: 4 step: 55, loss is 0.011321380734443665\n",
      "epoch: 4 step: 56, loss is 0.005026653409004211\n",
      "epoch: 4 step: 57, loss is 0.009119264781475067\n",
      "epoch: 4 step: 58, loss is 0.006276351865381002\n",
      "epoch: 4 step: 59, loss is 0.014371661469340324\n",
      "epoch: 4 step: 60, loss is 0.005472050979733467\n",
      "epoch: 4 step: 61, loss is 0.006916310638189316\n",
      "epoch: 4 step: 62, loss is 0.009219532832503319\n",
      "epoch: 4 step: 63, loss is 0.01698293536901474\n",
      "epoch: 4 step: 64, loss is 0.007250480353832245\n",
      "epoch: 4 step: 65, loss is 0.011000008322298527\n",
      "epoch: 4 step: 66, loss is 0.005420442670583725\n",
      "epoch: 4 step: 67, loss is 0.01000265497714281\n",
      "epoch: 4 step: 68, loss is 0.003807423636317253\n",
      "epoch: 4 step: 69, loss is 0.006241529248654842\n",
      "epoch: 4 step: 70, loss is 0.0033395707141608\n",
      "epoch: 4 step: 71, loss is 0.006379537284374237\n",
      "epoch: 4 step: 72, loss is 0.003263600170612335\n",
      "epoch: 4 step: 73, loss is 0.004982317332178354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 74, loss is 0.004326532129198313\n",
      "epoch: 4 step: 75, loss is 0.005442000459879637\n",
      "epoch: 4 step: 76, loss is 0.006924111861735582\n",
      "epoch: 4 step: 77, loss is 0.003923754207789898\n",
      "epoch: 4 step: 78, loss is 0.00524840597063303\n",
      "epoch: 4 step: 79, loss is 0.005871220491826534\n",
      "epoch: 4 step: 80, loss is 0.007262077648192644\n",
      "epoch: 4 step: 81, loss is 0.00391845079138875\n",
      "epoch: 4 step: 82, loss is 0.005579745396971703\n",
      "epoch: 4 step: 83, loss is 0.00516178272664547\n",
      "epoch: 4 step: 84, loss is 0.009186436422169209\n",
      "epoch: 4 step: 85, loss is 0.0052321976982057095\n",
      "epoch: 4 step: 86, loss is 0.007362195756286383\n",
      "epoch: 4 step: 87, loss is 0.0053515927866101265\n",
      "epoch: 4 step: 88, loss is 0.004112340975552797\n",
      "epoch: 4 step: 89, loss is 0.006318016909062862\n",
      "epoch: 4 step: 90, loss is 0.006404126062989235\n",
      "epoch: 4 step: 91, loss is 0.009488876909017563\n",
      "epoch: 4 step: 92, loss is 0.005417576991021633\n",
      "epoch: 4 step: 93, loss is 0.0051222206093370914\n",
      "epoch: 4 step: 94, loss is 0.0054349214769899845\n",
      "epoch: 4 step: 95, loss is 0.004782609175890684\n",
      "epoch: 4 step: 96, loss is 0.004597700200974941\n",
      "epoch: 4 step: 97, loss is 0.004002772271633148\n",
      "epoch: 4 step: 98, loss is 0.005616486072540283\n",
      "epoch: 4 step: 99, loss is 0.0038096033968031406\n",
      "epoch: 4 step: 100, loss is 0.005652832332998514\n",
      "epoch: 4 step: 101, loss is 0.004689442925155163\n",
      "epoch: 4 step: 102, loss is 0.00628129905089736\n",
      "epoch: 4 step: 103, loss is 0.003977509215474129\n",
      "epoch: 4 step: 104, loss is 0.021399719640612602\n",
      "epoch: 4 step: 105, loss is 0.01045086607336998\n",
      "epoch: 4 step: 106, loss is 0.006875925697386265\n",
      "epoch: 4 step: 107, loss is 0.005635102745145559\n",
      "epoch: 4 step: 108, loss is 0.006328296847641468\n",
      "epoch: 4 step: 109, loss is 0.004834883846342564\n",
      "epoch: 4 step: 110, loss is 0.003217835444957018\n",
      "epoch: 4 step: 111, loss is 0.005385279655456543\n",
      "epoch: 4 step: 112, loss is 0.0050014532171189785\n",
      "epoch: 4 step: 113, loss is 0.005674414802342653\n",
      "epoch: 4 step: 114, loss is 0.004454608075320721\n",
      "epoch: 4 step: 115, loss is 0.003925146535038948\n",
      "epoch: 4 step: 116, loss is 0.008641829714179039\n",
      "epoch: 4 step: 117, loss is 0.0038343933410942554\n",
      "epoch: 4 step: 118, loss is 0.003864394035190344\n",
      "epoch: 4 step: 119, loss is 0.00489220442250371\n",
      "epoch: 4 step: 120, loss is 0.005161412060260773\n",
      "epoch: 4 step: 121, loss is 0.004033040255308151\n",
      "epoch: 4 step: 122, loss is 0.005044364370405674\n",
      "epoch: 4 step: 123, loss is 0.004113017115741968\n",
      "epoch: 4 step: 124, loss is 0.004827640950679779\n",
      "epoch: 4 step: 125, loss is 0.004028943367302418\n",
      "epoch: 4 step: 126, loss is 0.0048376149497926235\n",
      "epoch: 4 step: 127, loss is 0.0037889217492192984\n",
      "epoch: 4 step: 128, loss is 0.00461830198764801\n",
      "epoch: 4 step: 129, loss is 0.004941473249346018\n",
      "epoch: 4 step: 130, loss is 0.00528187258169055\n",
      "epoch: 4 step: 131, loss is 0.00567352632060647\n",
      "epoch: 4 step: 132, loss is 0.0037096228916198015\n",
      "epoch: 4 step: 133, loss is 0.005263705737888813\n",
      "epoch: 4 step: 134, loss is 0.004771493375301361\n",
      "epoch: 4 step: 135, loss is 0.004845332819968462\n",
      "epoch: 4 step: 136, loss is 0.004510490223765373\n",
      "epoch: 4 step: 137, loss is 0.00443231500685215\n",
      "epoch: 4 step: 138, loss is 0.004251823760569096\n",
      "epoch: 4 step: 139, loss is 0.004941079765558243\n",
      "epoch: 4 step: 140, loss is 0.00511359004303813\n",
      "epoch: 4 step: 141, loss is 0.005226229317486286\n",
      "epoch: 4 step: 142, loss is 0.003736799815669656\n",
      "epoch: 4 step: 143, loss is 0.004717385862022638\n",
      "epoch: 4 step: 144, loss is 0.006195303983986378\n",
      "epoch: 4 step: 145, loss is 0.007837461307644844\n",
      "epoch: 4 step: 146, loss is 0.008032002486288548\n",
      "epoch: 4 step: 147, loss is 0.004531442187726498\n",
      "epoch: 4 step: 148, loss is 0.006327666807919741\n",
      "epoch: 4 step: 149, loss is 0.008451241068542004\n",
      "Train epoch time: 102636.674 ms, per step time: 688.837 ms\n",
      "train success\n"
     ]
    }
   ],
   "source": [
    "model.train(epoch_size, dataset, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "print(\"train success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b56379",
   "metadata": {},
   "source": [
    "# 测试评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81a6b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from [./ckpt/train_textcnn_42-4_149.ckpt].\n",
      "accuracy:  {'acc': 0.8056640625}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = './ckpt/train_textcnn_42-4_149.ckpt'\n",
    "dataset = instance.create_test_dataset(batch_size=batch_size)\n",
    "opt = nn.Adam(filter(lambda x: x.requires_grad, net.get_parameters()), \n",
    "              learning_rate=0.001, weight_decay=weight_decay)\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n",
    "net = TextCNN(vocab_len=instance.get_dict_len(),word_len=word_len,\n",
    "                  num_classes=num_classes,vec_length=vec_length)\n",
    "\n",
    "if checkpoint_path is not None:\n",
    "    param_dict = load_checkpoint(checkpoint_path)\n",
    "    print(\"load checkpoint from [{}].\".format(checkpoint_path))\n",
    "else:\n",
    "    param_dict = load_checkpoint(checkpoint_path)\n",
    "    print(\"load checkpoint from [{}].\".format(checkpoint_path))\n",
    "\n",
    "load_param_into_net(net, param_dict)\n",
    "net.set_train(False)\n",
    "model = Model(net, loss_fn=loss, metrics={'acc': Accuracy()})\n",
    "\n",
    "acc = model.eval(dataset)\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743485d0",
   "metadata": {},
   "source": [
    "# 在线测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caee6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = sentence.replace('\\n','')\\\n",
    "                                    .replace('\"','')\\\n",
    "                                    .replace('\\'','')\\\n",
    "                                    .replace('.','')\\\n",
    "                                    .replace(',','')\\\n",
    "                                    .replace('[','')\\\n",
    "                                    .replace(']','')\\\n",
    "                                    .replace('(','')\\\n",
    "                                    .replace(')','')\\\n",
    "                                    .replace(':','')\\\n",
    "                                    .replace('--','')\\\n",
    "                                    .replace('-',' ')\\\n",
    "                                    .replace('\\\\','')\\\n",
    "                                    .replace('0','')\\\n",
    "                                    .replace('1','')\\\n",
    "                                    .replace('2','')\\\n",
    "                                    .replace('3','')\\\n",
    "                                    .replace('4','')\\\n",
    "                                    .replace('5','')\\\n",
    "                                    .replace('6','')\\\n",
    "                                    .replace('7','')\\\n",
    "                                    .replace('8','')\\\n",
    "                                    .replace('9','')\\\n",
    "                                    .replace('`','')\\\n",
    "                                    .replace('=','')\\\n",
    "                                    .replace('$','')\\\n",
    "                                    .replace('/','')\\\n",
    "                                    .replace('*','')\\\n",
    "                                    .replace(';','')\\\n",
    "                                    .replace('<b>','')\\\n",
    "                                    .replace('%','')\\\n",
    "                                    .replace(\"  \",\" \")\n",
    "    sentence = sentence.split(' ')\n",
    "    maxlen = word_len\n",
    "    vector = [0]*maxlen\n",
    "    for index, word in enumerate(sentence):\n",
    "        if index >= maxlen:\n",
    "            break\n",
    "        if word not in instance.Vocab.keys():\n",
    "            print(word,\"单词未出现在字典中\")\n",
    "        else:\n",
    "            vector[index] = instance.Vocab[word]\n",
    "    sentence = vector\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def inference(review_en):\n",
    "    review_en = preprocess(review_en)\n",
    "    input_en = Tensor(np.array([review_en]).astype(np.int32))\n",
    "    output = net(input_en)\n",
    "    if np.argmax(np.array(output[0])) == 1:\n",
    "        print(\"Positive comments\")\n",
    "    else:\n",
    "        print(\"Negative comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f40e01e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments\n"
     ]
    }
   ],
   "source": [
    "review_en = \"the movie make my heart relief\"\n",
    "inference(review_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd725d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments\n"
     ]
    }
   ],
   "source": [
    "review_en = \"just boring and make me sleepy\"\n",
    "inference(review_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23698c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments\n"
     ]
    }
   ],
   "source": [
    "review_en = \"interesting and funny movie\"\n",
    "inference(review_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106d5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envtf2)",
   "language": "python",
   "name": "envtf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
